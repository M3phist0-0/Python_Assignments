{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Assignment - Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the data into a pandas dataframe (you may get a warning, you can get rid of it by setting low_memory=False). \n",
    "\n",
    "### Print the first 10 rows and print a random sampling of the rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     status  bed bath  acre_lot           city        state  zip_code  \\\n",
      "0  for_sale  3.0  2.0      0.12       Adjuntas  Puerto Rico     601.0   \n",
      "1  for_sale  4.0  2.0      0.08       Adjuntas  Puerto Rico     601.0   \n",
      "2  for_sale  2.0  1.0      0.15     Juana Diaz  Puerto Rico     795.0   \n",
      "3  for_sale  4.0  2.0      0.10          Ponce  Puerto Rico     731.0   \n",
      "4  for_sale  6.0  2.0      0.05       Mayaguez  Puerto Rico     680.0   \n",
      "5  for_sale  4.0  3.0      0.46  San Sebastian  Puerto Rico     612.0   \n",
      "6  for_sale  3.0  1.0      0.20         Ciales  Puerto Rico     639.0   \n",
      "7  for_sale  3.0  2.0      0.08          Ponce  Puerto Rico     731.0   \n",
      "8  for_sale  2.0  1.0      0.09          Ponce  Puerto Rico     730.0   \n",
      "9  for_sale  5.0  3.0      7.46     Las Marias  Puerto Rico     670.0   \n",
      "\n",
      "   house_size prev_sold_date     price  \n",
      "0       920.0            NaN  105000.0  \n",
      "1      1527.0            NaN   80000.0  \n",
      "2       748.0            NaN   67000.0  \n",
      "3      1800.0            NaN  145000.0  \n",
      "4         NaN            NaN   65000.0  \n",
      "5      2520.0            NaN  179000.0  \n",
      "6      2040.0            NaN   50000.0  \n",
      "7      1050.0            NaN   71600.0  \n",
      "8      1092.0            NaN  100000.0  \n",
      "9      5403.0            NaN  300000.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = \n",
    "p_df = pd.read_csv('realtor-data.csv', low_memory=False)\n",
    "\n",
    "print(p_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) You should always check how many null values there are in your data as well as the data types of the data you're working with. Often you will come across data that looks correct but isn't the right data type. \n",
    "\n",
    "### Check the number of null values for every column and check the data types as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) We have 3 columns that looked right when checking the data but aren't the right data type and we'll correct it. \n",
    "\n",
    "### Cast the columns bed, bath and price to float. Values that cannot be casted to float, like \"hello\" should be turned into NaN. \n",
    "\n",
    "### Check the data types again to make sure the conversion was successfull.\n",
    "\n",
    "\n",
    "\n",
    "### Get a count of the number of NaNs in bed, bath and price columns. \n",
    "\n",
    "### You should get 216535, 194215 and 110 respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Check the number of unique values in the bed, bath and state columns. \n",
    "\n",
    "### You should get 49, 42 and 19 respectively\n",
    "\n",
    "### Print the uniques values for bed, bath and state. What do you notice about the unique values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) We want to see which state has the largest number of properties for sale. \n",
    "\n",
    "### Print a count of the number of properties in each state/territory. \n",
    "\n",
    "### We want to make sure that we're getting unique listings, so drop any duplicate rows and print the count of the number of properties. What do you notice about the number of properties in each state ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) We now want to look for patterns in our data, find the 5 dates when the most houses were sold. What do you notice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Now we want to create a simple but effective summary of the properties that are for sale. \n",
    "\n",
    "### Let's create a summary table that contains the average home size and price, every state and each city within a state. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Your output should be this:\n",
    "# \t\t                          house_size\tprice\n",
    "# state\t            city\t\t\n",
    "# Connecticut\t    Andover\t     1653.750000\t2.539500e+05\n",
    "#                   Ansonia\t     1848.172414\t2.917902e+05\n",
    "#                   Ashford\t     1638.888889\t1.959045e+05\n",
    "#                   Avon\t     2929.878788\t5.824611e+05\n",
    "#                   Barkhamsted\t 2703.538462\t3.383238e+05\n",
    "# ...\t...\t...\t...\n",
    "# Virgin Islands\tSaint Thomas 3435.025641\t1.185128e+06\n",
    "# Virginia\t        Cape Charles\t     NaN\t7.130000e+05\n",
    "#                   Chincoteague\t     NaN\t1.620000e+05\n",
    "# West Virginia\t    Wyoming\t     1860.000000\t6.250000e+04\n",
    "# Wyoming\t        Cody\t     1935.000000\t5.350000e+05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
