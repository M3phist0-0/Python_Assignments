{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Assignment - Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load the data into a pandas dataframe (you may get a warning, you can get rid of it by setting low_memory=False). \n",
    "\n",
    "### Print the first 10 rows and print a random sampling of the rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n",
      "     status  bed bath  acre_lot           city        state  zip_code  \\\n",
      "0  for_sale  3.0  2.0      0.12       Adjuntas  Puerto Rico     601.0   \n",
      "1  for_sale  4.0  2.0      0.08       Adjuntas  Puerto Rico     601.0   \n",
      "2  for_sale  2.0  1.0      0.15     Juana Diaz  Puerto Rico     795.0   \n",
      "3  for_sale  4.0  2.0      0.10          Ponce  Puerto Rico     731.0   \n",
      "4  for_sale  6.0  2.0      0.05       Mayaguez  Puerto Rico     680.0   \n",
      "5  for_sale  4.0  3.0      0.46  San Sebastian  Puerto Rico     612.0   \n",
      "6  for_sale  3.0  1.0      0.20         Ciales  Puerto Rico     639.0   \n",
      "7  for_sale  3.0  2.0      0.08          Ponce  Puerto Rico     731.0   \n",
      "8  for_sale  2.0  1.0      0.09          Ponce  Puerto Rico     730.0   \n",
      "9  for_sale  5.0  3.0      7.46     Las Marias  Puerto Rico     670.0   \n",
      "\n",
      "   house_size prev_sold_date     price  \n",
      "0       920.0            NaN  105000.0  \n",
      "1      1527.0            NaN   80000.0  \n",
      "2       748.0            NaN   67000.0  \n",
      "3      1800.0            NaN  145000.0  \n",
      "4         NaN            NaN   65000.0  \n",
      "5      2520.0            NaN  179000.0  \n",
      "6      2040.0            NaN   50000.0  \n",
      "7      1050.0            NaN   71600.0  \n",
      "8      1092.0            NaN  100000.0  \n",
      "9      5403.0            NaN  300000.0  \n",
      "Random Sampling:\n",
      "           status  bed bath  acre_lot             city          state  \\\n",
      "933207   for_sale  2.0  2.0       NaN          Yonkers       New York   \n",
      "1059061  for_sale  3.0  3.0      0.06            Bronx       New York   \n",
      "125917   for_sale  1.0  1.0       NaN          Belmont  Massachusetts   \n",
      "9792     for_sale  3.0  2.0      0.09       Rio Grande    Puerto Rico   \n",
      "1235091  for_sale  3.0  1.0      0.33      West Hurley       New York   \n",
      "799486   for_sale  4.0  3.0      0.09  North Arlington     New Jersey   \n",
      "296381   for_sale  3.0  1.0      0.34         Fryeburg          Maine   \n",
      "507506   for_sale  4.0  3.0      0.12     Little Ferry     New Jersey   \n",
      "703408   for_sale  3.0  2.0      0.07         Hamilton     New Jersey   \n",
      "1244103  for_sale  NaN  NaN      0.83         Catskill       New York   \n",
      "\n",
      "         zip_code  house_size prev_sold_date     price  \n",
      "933207    10710.0      1100.0            NaN  295000.0  \n",
      "1059061   10464.0      1500.0            NaN  689000.0  \n",
      "125917     2478.0       527.0     2010-05-04  369900.0  \n",
      "9792        745.0      1090.0            NaN  156000.0  \n",
      "1235091   12491.0      1108.0     1982-03-01   75000.0  \n",
      "799486     7031.0         NaN            NaN  680000.0  \n",
      "296381     4037.0       846.0            NaN  259900.0  \n",
      "507506     7643.0         NaN            NaN  599000.0  \n",
      "703408     8611.0      1296.0            NaN  199000.0  \n",
      "1244103   12414.0      1656.0            NaN   79000.0  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/realtor-data.csv'\n",
    "p_df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "print('First 10 rows:')\n",
    "print(p_df.head(10))\n",
    "\n",
    "print('Random Sampling:')\n",
    "print(p_df.sample(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) You should always check how many null values there are in your data as well as the data types of the data you're working with. Often you will come across data that looks correct but isn't the right data type. \n",
    "\n",
    "### Check the number of null values for every column and check the data types as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Count:\n",
      "status                 0\n",
      "bed               216467\n",
      "bath              194206\n",
      "acre_lot          357467\n",
      "city                 191\n",
      "state                  0\n",
      "zip_code             479\n",
      "house_size        450112\n",
      "prev_sold_date    686293\n",
      "price                108\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count = p_df.isnull().sum()\n",
    "print('Null Count:')\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) We have 3 columns that looked right when checking the data but aren't the right data type and we'll correct it. \n",
    "\n",
    "### Cast the columns bed, bath and price to float. Values that cannot be casted to float, like \"hello\" should be turned into NaN. \n",
    "\n",
    "### Check the data types again to make sure the conversion was successfull.\n",
    "\n",
    "\n",
    "\n",
    "### Get a count of the number of NaNs in bed, bath and price columns. \n",
    "\n",
    "### You should get 216535, 194215 and 110 respectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status             object\n",
      "bed               float64\n",
      "bath              float64\n",
      "acre_lot          float64\n",
      "city               object\n",
      "state              object\n",
      "zip_code          float64\n",
      "house_size        float64\n",
      "prev_sold_date     object\n",
      "price             float64\n",
      "dtype: object\n",
      "           status   bed  bath  acre_lot          city        state  zip_code  \\\n",
      "0        for_sale   3.0   2.0      0.12      Adjuntas  Puerto Rico     601.0   \n",
      "1        for_sale   4.0   2.0      0.08      Adjuntas  Puerto Rico     601.0   \n",
      "2        for_sale   2.0   1.0      0.15    Juana Diaz  Puerto Rico     795.0   \n",
      "3        for_sale   4.0   2.0      0.10         Ponce  Puerto Rico     731.0   \n",
      "4        for_sale   6.0   2.0      0.05      Mayaguez  Puerto Rico     680.0   \n",
      "...           ...   ...   ...       ...           ...          ...       ...   \n",
      "1401061  for_sale   NaN   NaN    155.00    Perrysburg     New York   14129.0   \n",
      "1401062  for_sale   4.0   2.0      0.36  Silver Creek     New York   14136.0   \n",
      "1401063  for_sale  10.0   4.0      0.43       Brocton     New York   14716.0   \n",
      "1401064  for_sale   2.0   2.0      0.14       Dunkirk     New York   14048.0   \n",
      "1401065  for_sale   5.0   2.0      0.14        Angola     New York   14006.0   \n",
      "\n",
      "         house_size prev_sold_date     price  \n",
      "0             920.0            NaN  105000.0  \n",
      "1            1527.0            NaN   80000.0  \n",
      "2             748.0            NaN   67000.0  \n",
      "3            1800.0            NaN  145000.0  \n",
      "4               NaN            NaN   65000.0  \n",
      "...             ...            ...       ...  \n",
      "1401061         NaN            NaN  325000.0  \n",
      "1401062      2026.0     2000-09-01  187900.0  \n",
      "1401063      4802.0     1994-12-01  120000.0  \n",
      "1401064      1568.0     2003-04-15   92000.0  \n",
      "1401065      1908.0     2016-01-12   99900.0  \n",
      "\n",
      "[1401066 rows x 10 columns]\n",
      "bed      216535\n",
      "bath     194215\n",
      "price       110\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "p_df[['bed', 'bath', 'price']] = p_df[['bed', 'bath', 'price']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(p_df.dtypes)\n",
    "print(p_df)\n",
    "nan_count = p_df[['bed', 'bath', 'price']].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Check the number of unique values in the bed, bath and state columns. \n",
    "\n",
    "### You should get 49, 42 and 19 respectively\n",
    "\n",
    "### Print the uniques values for bed, bath and state. What do you notice about the unique values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed      49\n",
      "bath     42\n",
      "state    19\n",
      "dtype: int64\n",
      "Unique values for 'bed': [  3.   4.   2.   6.   5.   1.   9.  nan   7.   8.  12.  13.  10.  11.\n",
      "  33.  24.  28.  14.  18.  20.  16.  15.  19.  17.  40.  21.  86.  31.\n",
      "  27.  42.  60.  22.  32.  99.  49.  29.  30.  23.  46.  36.  68. 123.\n",
      "  25.  47.  inf  35.  38.  64.  48.  75.]\n",
      "Unique values for 'bath': [  2.   1.   3.   5.   4.   7.   6.  nan   8.   9.  10.  12.  13.  35.\n",
      "  11.  16.  15.  18.  20.  14.  36.  25.  17.  19.  56.  42.  51.  28.\n",
      " 198.  22.  33.  27.  30.  29.  24.  46.  21. 123.  39.  43.  32.  45.\n",
      "  64.]\n",
      "Unique values for 'state': ['Puerto Rico' 'Virgin Islands' 'Massachusetts' 'Connecticut'\n",
      " 'New Hampshire' 'Vermont' 'New Jersey' 'New York' 'South Carolina'\n",
      " 'Tennessee' 'Rhode Island' 'Virginia' 'Wyoming' 'Maine' 'Georgia'\n",
      " 'Pennsylvania' 'West Virginia' 'Delaware' 'Louisiana']\n"
     ]
    }
   ],
   "source": [
    "unique_value = p_df[['bed', 'bath', 'state']].nunique()\n",
    "print(unique_value)\n",
    "\n",
    "print(\"Unique values for 'bed':\", p_df['bed'].unique())\n",
    "print(\"Unique values for 'bath':\", p_df['bath'].unique())\n",
    "print(\"Unique values for 'state':\", p_df['state'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) We want to see which state has the largest number of properties for sale. \n",
    "\n",
    "### Print a count of the number of properties in each state/territory. \n",
    "\n",
    "### We want to make sure that we're getting unique listings, so drop any duplicate rows and print the count of the number of properties. What do you notice about the number of properties in each state ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "New York          67160\n",
      "New Jersey        32601\n",
      "Connecticut       13753\n",
      "Massachusetts     10056\n",
      "Pennsylvania       9549\n",
      "Maine              4938\n",
      "New Hampshire      3431\n",
      "Rhode Island       3332\n",
      "Puerto Rico        2651\n",
      "Vermont            2544\n",
      "Delaware           1290\n",
      "Virgin Islands      730\n",
      "Virginia              7\n",
      "Georgia               5\n",
      "South Carolina        1\n",
      "Tennessee             1\n",
      "Wyoming               1\n",
      "West Virginia         1\n",
      "Louisiana             1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "p_df_unique = p_df.drop_duplicates()\n",
    "\n",
    "state_counts = p_df_unique['state'].value_counts()\n",
    "\n",
    "print(state_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) We now want to look for patterns in our data, find the 5 dates when the most houses were sold. What do you notice ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_sold_date\n",
      "2022-04-15    68\n",
      "2022-04-29    58\n",
      "2022-03-31    57\n",
      "2022-04-01    54\n",
      "2022-02-28    54\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "p_df_unique.loc[:,['prev_sold_date']] = pd.to_datetime(p_df_unique['prev_sold_date'], errors='coerce')\n",
    "\n",
    "date_counts = p_df_unique['prev_sold_date'].value_counts()\n",
    "\n",
    "five_dates = date_counts.head(5)\n",
    "print(five_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Now we want to create a simple but effective summary of the properties that are for sale. \n",
    "\n",
    "### Let's create a summary table that contains the average home size and price, every state and each city within a state. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              house_size         price\n",
      "state          city                                   \n",
      "Connecticut    Andover       1653.750000  2.539500e+05\n",
      "               Ansonia       1848.172414  2.917902e+05\n",
      "               Ashford       1638.888889  1.959045e+05\n",
      "               Avon          2929.878788  5.824611e+05\n",
      "               Barkhamsted   2703.538462  3.383238e+05\n",
      "...                                  ...           ...\n",
      "Virgin Islands Saint Thomas  3435.025641  1.185128e+06\n",
      "Virginia       Cape Charles          NaN  7.130000e+05\n",
      "               Chincoteague          NaN  1.620000e+05\n",
      "West Virginia  Wyoming       1860.000000  6.250000e+04\n",
      "Wyoming        Cody          1935.000000  5.350000e+05\n",
      "\n",
      "[4308 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "p_df_unique.loc[:,['house_size', 'price']] = p_df_unique[['house_size', 'price']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "summary_table = p_df_unique.groupby(['state', 'city'])[['house_size', 'price']].mean()\n",
    "\n",
    "print(summary_table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Your output should be this:\n",
    "# \t\t                          house_size\tprice\n",
    "# state\t            city\t\t\n",
    "# Connecticut\t    Andover\t     1653.750000\t2.539500e+05\n",
    "#                   Ansonia\t     1848.172414\t2.917902e+05\n",
    "#                   Ashford\t     1638.888889\t1.959045e+05\n",
    "#                   Avon\t     2929.878788\t5.824611e+05\n",
    "#                   Barkhamsted\t 2703.538462\t3.383238e+05\n",
    "# ...\t...\t...\t...\n",
    "# Virgin Islands\tSaint Thomas 3435.025641\t1.185128e+06\n",
    "# Virginia\t        Cape Charles\t     NaN\t7.130000e+05\n",
    "#                   Chincoteague\t     NaN\t1.620000e+05\n",
    "# West Virginia\t    Wyoming\t     1860.000000\t6.250000e+04\n",
    "# Wyoming\t        Cody\t     1935.000000\t5.350000e+05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
